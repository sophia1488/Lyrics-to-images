{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Lyric Prompt by ChatGPT"
      ],
      "metadata": {
        "id": "tKEIeSZxM8fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xeyn5l84jvyV",
        "outputId": "52ae8f7a-a3fe-4a23-f8f5-f5b2a7fdad11"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.26.5.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (3.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.5-py3-none-any.whl size=67620 sha256=4c30c4611f3c1d2ba1a1db3a05d15bb86749756b23d8f3286646bc4eb337ac12\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/47/99/8273a59fbd59c303e8ff175416d5c1c9c03a2e83ebf7525a99\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.26.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from string import digits\n",
        "openai.api_key = \"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\"\n",
        "filename = \"youraisemeup\"\n",
        "lyric_file = \"/content/drive/MyDrive/10615Lyric/{}.txt\".format(filename)\n",
        "output_lyric_file = \"/content/drive/MyDrive/10615Lyric/{}_pro.txt\".format(filename)"
      ],
      "metadata": {
        "id": "-Okew1v-M7iW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seperate_prompt = \"Separate into sentences and number:\\n\"\n",
        "remove_prompt = \"\\n Synonyms: \\n Remove connecting words: \\n\""
      ],
      "metadata": {
        "id": "MqgCEMejVLp3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_lyric(lyric_path):\n",
        "  with open(lyric_file) as f:\n",
        "    lines = f.readlines()\n",
        "  return \" \".join(l for l in lines)\n",
        "\n",
        "def write_lyrics(processed_lyrics, output_path):\n",
        "  with open(output_path, \"w\") as text_file:\n",
        "    text_file.write(processed_lyrics)\n",
        "  text_file.close()\n",
        "\n",
        "  \n",
        "def create_prompts(prompt_input, model=\"text-davinci-003\", temp=0.7):\n",
        "    response = responses = openai.Completion.create(\n",
        "      model=model,\n",
        "      prompt=prompt_input,\n",
        "      temperature=temp,\n",
        "      max_tokens=500,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0)\n",
        "    return response['choices'][0]['text']\n",
        "\n",
        "def lyric_processing(lyric_str, gpt_model=\"text-davinci-003\", add_style=None):\n",
        "  prompt1 = seperate_prompt+lyric_str\n",
        "  response1 = create_prompts(prompt1).replace(\"\\n\", \"\").replace(\"?\", \".\")\n",
        "  response1 = response1.translate(str.maketrans('', '', digits))\n",
        "  if \"Sentence : \" in response1:\n",
        "    indiv_prompts = response1.split(\"Sentence : \")\n",
        "  else:\n",
        "    indiv_prompts = response1.split(\". \")\n",
        "  print(indiv_prompts)\n",
        "  output_prompts = []\n",
        "  for s in indiv_prompts:\n",
        "    if s == '':\n",
        "      pass\n",
        "    else:\n",
        "      prompt2 = s+remove_prompt\n",
        "      prompt2_output = create_prompts(prompt2).replace(\"\\n\", \", \")\n",
        "      prompt2_output = prompt2_output.replace(\" , \", \"\")\n",
        "      if s[-1] != \".\":\n",
        "        s += \".\"\n",
        "      prompt2_output = s+\", \"+prompt2_output\n",
        "      print(prompt2_output)\n",
        "      output_prompts.append(prompt2_output)\n",
        "    \n",
        "  if add_style:\n",
        "    return \"\\n\".join(\"{} style: \".format(add_style)+l for l in output_prompts)\n",
        "\n",
        "  return \"\\n\".join(l for l in output_prompts)\n",
        "\n"
      ],
      "metadata": {
        "id": "N9Va95oFUUfR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lyrics to Input Run"
      ],
      "metadata": {
        "id": "InHG_2ufcrxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lyrics = read_lyric(lyric_file)\n",
        "processed_lyrics = lyric_processing(lyrics)\n",
        "write_lyrics(processed_lyrics, output_lyric_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgXo_4rjZcTa",
        "outputId": "38c63cf2-fb19-4195-9ed9-8dcbca3e6c9f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', 'When I am down and, oh my soul, so weary, when troubles come and my heart burdened be, then I am still and wait here in the silence until You come and sit awhile with me', '', 'You raise me up, so I can stand on mountains', '', 'You raise me up, to walk on stormy seas', '', 'I am strong, when I am on your shoulders', '', 'You raise me up to more than I can be.']\n",
            "When I am down and, oh my soul, so weary, when troubles come and my heart burdened be, then I am still and wait here in the silence until You come and sit awhile with me., Down, weary, troubles, heart, still, wait, silence, come, sit.,Depressed, exhausted, difficulties, chest, stationary, pause, hush, approach, perch.\n",
            "You raise me up, so I can stand on mountains., , Elevate, Uplift, Exalt, Boost, Enhance, Lift, Raise, Empower\n",
            "You raise me up, to walk on stormy seas., Raise, Walk, Stormy, Seas\n",
            "I am strong, when I am on your shoulders., I, strong, shoulders.\n",
            "You raise me up to more than I can be., Elevate, Enhance, Uplift, Exalt, Boost, Magnify\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Processed Lyrics to Image by Stable Diffusion"
      ],
      "metadata": {
        "id": "ASwv__W2NFiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up Environment"
      ],
      "metadata": {
        "id": "edKL_hMUc0KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vicgalle/stable-diffusion-aesthetic-gradients\n",
        "%cd stable-diffusion-aesthetic-gradients\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiOoyr2-X18b",
        "outputId": "208bd72a-f3f9-4ff7-9e2e-8f42742ae6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'stable-diffusion-aesthetic-gradients' already exists and is not an empty directory.\n",
            "/content/stable-diffusion-aesthetic-gradients\n",
            "\u001b[0m\u001b[01;34m.\u001b[0m/                      environment.yaml     README.md\n",
            "\u001b[01;34m..\u001b[0m/                     \u001b[01;34m.git\u001b[0m/                \u001b[01;34mreference_images\u001b[0m/\n",
            "\u001b[01;34maesthetic_embeddings\u001b[0m/   \u001b[01;34mldm\u001b[0m/                 \u001b[01;34mscripts\u001b[0m/\n",
            "\u001b[01;34massets\u001b[0m/                 LICENSE              setup.py\n",
            "condacolab_install.log  main.py              Stable_Diffusion_v1_Model_Card.md\n",
            "\u001b[01;34mconfigs\u001b[0m/                \u001b[01;34mmodels\u001b[0m/              \u001b[01;34mtest_face\u001b[0m/\n",
            "\u001b[01;34mdata\u001b[0m/                   notebook_helpers.py  \u001b[01;34mtest_segmentation\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env create -f environment.yaml\n",
        "!conda activate ldm\n",
        "!conda install pytorch torchvision cudatoolkit=11.3 -c pytorch\n",
        "!pip install GPUtil\n",
        "!pip install blobfile\n",
        "!pip install facenet-pytorch"
      ],
      "metadata": {
        "id": "3OCc5nQja7qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running model with specified model path"
      ],
      "metadata": {
        "id": "9Ek2m4yzc438"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up\n",
        "!git clone https://github.com/sophia1488/Lyrics-to-images\n",
        "ckpt=\"../Universal-Guided-Diffusion/sd-v1-4.ckpt\"\n",
        "step=20\n",
        "lyrics_file = output_lyric_file\n",
        "# run the entire song\n",
        "!python scripts/lyrics2imgs.py --lyrics $lyrics_file --plms --seed 332 --aesthetic_steps $step --aesthetic_embedding aesthetic_embeddings/sac_8plus.pt --ckpt $ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oiRSSEwaIZk",
        "outputId": "836381ae-6254-49a5-b5d5-c0589ac43fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 0: `python scripts/face_detection.py --indexes 0 --text \"Headshot of a person with blonde hair with space background\" --optim_forward_guidance --fr_crop --optim_num_steps 2 --optim_forward_guidance_wt 20000 --optim_original_conditioning --ddim_steps 500 --optim_folder ./test_face/text_type_4/ --ckpt <Path to stable diffusion model>'\n"
          ]
        }
      ]
    }
  ]
}